{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pickle #To unpack the file\n",
    "import matplotlib.pyplot as plt #For plotting\n",
    "import torch.optim as optim #Parameter optimization functions\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset #Creating the Dataset and DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms #Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#Check GPU status\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dataLoader class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is pickled which means that the objects are converted into a byte stream. We will unpickle the object to get back the original data. (https://www.cs.toronto.edu/~kriz/cifar.html). Below is the Dataset class which can be used in torch.utils.data.dataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cifarDataset(Dataset):\n",
    "    def __init__(self, filePath, transform=None):\n",
    "        self.images, self.labels = self.__loadImages__(filePath)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __loadImages__(self, filePath):\n",
    "        object = self.__unpickle__(filePath) #Extract our dataset\n",
    "        X = object[b'data']\n",
    "        X = X.reshape(len(object[b'data']),3,32,32) #Reshape to Color and the corresponding XY coordinates\n",
    "        l = object[b'labels']\n",
    "        return(X,l)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        #print(\"Before permute\", image.shape)\n",
    "        image = np.transpose(image, (1,2,0)) #Permute because transforms.ToTensor converts HWC to CHW\n",
    "        #print(\"After permute\", image.shape )\n",
    "        image = transforms.ToTensor()(image)\n",
    "        #print(\"ToTensor\", image.shape)\n",
    "        #print(\"Before\", image)\n",
    "        image = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(image) #Normalize our image\n",
    "        #print(\"After\", image)\n",
    "        sample = {'image':image, 'label':self.labels[idx]}\n",
    "        return(sample)\n",
    "        \n",
    "    def __unpickle__(self, file):\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(img, label='Not labeled'):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    img = img.permute(1,2,0)\n",
    "    plt.imshow(img)\n",
    "    plt.xlabel(label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabel(number):\n",
    "    names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    return(names[number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1 = cifarDataset(filePath='data/cifar-10-batches-py/data_batch_1')\n",
    "batch2 = cifarDataset(filePath='data/cifar-10-batches-py/data_batch_2')\n",
    "batch3 = cifarDataset(filePath='data/cifar-10-batches-py/data_batch_3')\n",
    "batch4 = cifarDataset(filePath='data/cifar-10-batches-py/data_batch_4')\n",
    "batch5 = cifarDataset(filePath='data/cifar-10-batches-py/data_batch_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate our training dataset\n",
    "batches = torch.utils.data.ConcatDataset([batch1,batch2, batch3, batch4, batch5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the dataLoader to extract images from our dataset\n",
    "trainloader = DataLoader(batches, batch_size=5, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testBatch = cifarDataset(filePath='data/cifar-10-batches-py/test_batch')\n",
    "#Create the dataLoader for our test set\n",
    "testloader = DataLoader(testBatch, batch_size=1, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch information:  0 torch.Size([5, 3, 32, 32]) tensor([5, 1, 8, 4, 5])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEKCAYAAADdIIPUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztnXmwnGeV3p/Te99903Itydosy9YYb8hmMXbMDGEYMhMgCVOmKpSTOONJAlVD1UxVCFMVSFX+YJIAxR8ppkzsjEkxLAEcXAlJABdgyDCyhce2bORVSLKs5Wq7ulvfXk/+6NYgy+/z3tbWV/b7/KpUuvc9/fZ3+v2+c7/u9+lzjrk7hBDpkVluB4QQy4OCX4hEUfALkSgKfiESRcEvRKIo+IVIFAW/EImi4BciURT8QiRK7kImm9n7AHwRQBbAf3H3z8YeX+gveHmkFLS1wL9pmMmSv1GxbyeacVtkmrdaEWN4YiaX5XMiNJuRY0XIZM/9tbUakWMZvwd4M3KoZuSc5cI+uvE51uSvyxvckdG+MrUND/SHj5Xhl75FLpBWc5HaKjVum65y/+vncRmwS39xpoJ6pRa5QH7NeQe/mWUB/GcAfxfAAQCPm9nD7v5LNqc8UsI7P/a2oG2xWaXH6hsNn9xmvU7nZDMFanPna1Of4Sew1Qofr29skM6JvbmaPjXLZ0UCvG8gT21WC4/PnuSvK5Pro7b6LA+ExnSD2oorwq/bM/yc2Sy/HOvH5qntrpuuo7bfue2twfFs3wSdkwd/XYundlPbU/ufo7aH9/BzfWQxvMbNBr8GGuS0/M1Xf07nnM2FvO2/FcBL7r7H3WsAvg7gAxfwfEKIHnIhwb8GwCtn/H6gMyaEeANwIcEfek/yujcjZnavme00s521ef6WTwjRWy4k+A8AWHfG72sBHDz7Qe5+n7tvd/fthX7+WVUI0VsuJPgfB7DFzDaaWQHAXQAevjhuCSEuNee92+/uDTP7OID/i7bU94C7PxudZECGSD21hQU6LVMYCo7PzVfonFKZ75TWYrJXRNoaKId3xWsNssUOoNHgO8dMDgOAnPF3SQuz3MnB/rCUWijz1zx3kq8jKlw1aXGBBpXZsLHcX6RzMlW+HhvI2gPADdfeSG3N3Irg+MIsPy+InLPqdEQGnOFrPFDltkOV8PnMFLiEbBlyDUSk1LO5IJ3f3b8H4HsX8hxCiOVB3/ATIlEU/EIkioJfiERR8AuRKAp+IRLlgnb7z5ViNoMNw+EknWKBSxTTRIqaq3HZ6OjJU9SW6wvLYQDgef6caIb/VrYW+TcXG5GUrViC0XyVJ+J48MuVbXKFsC/ZAj/V/WUu5y3McT3Pm1ziHCiHz3M2H0lWqXKJ7T233Ext61atp7ZKhkiE+Rk659Qilz4XKvx8Nqtcnm1EpMVWMSzblfv5OZs9Fk4UarUiWvVZ6M4vRKIo+IVIFAW/EImi4BciURT8QiRKT3f7M40WytPhXezbrxig8woTY8Fx618XHAeAF199ldoee+klajsSyVYxhHewvcR3gLOIlBNb5H97bYarFflyuC4dAJqYNFfjZbCyDZ40Y+DJJaVB7n+Z1AUsV/mcVaP8cty6/gpqazhXW/IWvt5aTb6+83OHqG1hjqsE1RpXCYqlSMm5QnhNGpEknUadqAfn0HVbd34hEkXBL0SiKPiFSBQFvxCJouAXIlEU/EIkSk+lPm8BzbmwFDGR5ZLS5OrVwfHM6FV0zsY13HbNVddT2492PU1tO/e9EBxvRhr2eIb/fW1W+fKPl0eobWaa1zu0cvh4/QNczqvM8wSdWHutXD9PIhkuhY+Xm+JS6uaxyL1o8QQ11Rf5CSgWwolac4e5nHfkuX3UNj/LJcJMga9HNhvpskQ6BFVqXELuI23IMpnuW8fpzi9Eoij4hUgUBb8QiaLgFyJRFPxCJIqCX4hEuSCpz8z2AphFO5es4e7boxNaQJOUpms1whlzAGCkDttCpGZaLs8z365cNUxtv9fPJbYWkcRePPa6/qR/S7PAfTxR4XXdfIifGqvxv9nV46RNVoavbyYiR/aNcLmpv8ifs1AntfrmeG3C/CCXI+emuDQ3GpEx6/XwdbBwjEuHlaPHqa2V4+tRGuEZnCODvDZkqTIXHJ+r8LXKtMJ++OsbZVMuhs7/bnc/dhGeRwjRQ/S2X4hEudDgdwDfN7NfmNm9F8MhIURvuNC3/be5+0EzWwngB2b2nLs/euYDOn8U7gWAwUFeL18I0Vsu6M7v7gc7/08BeAjArYHH3Ofu2919e7nMN7+EEL3lvIPfzPrNbPD0zwDeC+CZi+WYEOLSciFv+1cBeMjMTj/PX7r7/4lNaDlvd7RY5zLJLJG2Zhu8KGVfH/+7NjDMi4VeMb6K2v7h7XcEx5/Y9dd0zjP7uAxYb3DZaGRkiNoWK7wYZKUelvpmjnLZqBGRh4YneMZcvcmz2OaOhs/NZIu365qd5q9r3ytHqW10lMu6xVJYuq3MhttdAUC1yv2oZfhalTL8Y22zwZ+zrz8sVfbF7s0ePs8ZUjg1xHkHv7vvAXDD+c4XQiwvkvqESBQFvxCJouAXIlEU/EIkioJfiETpaQHPerOFqblwP7Nde3luUGEs3JMvUwpnQwFAq8klpRqvIQnL8eyrieGwHHnj+nAvQQDwOV7wsRmRKquRnmvVIi+42bCw/1nnhR2LLW7Lkqw4ACgZX+PcwnRwfLKfP99Clfe6ez4ima6N9HkkbR4xPcOvnVeOc1luDvziGZrn/h8v8vvs7HjYthgrrLoY9qNFsv1C6M4vRKIo+IVIFAW/EImi4BciURT8QiRKT3f7WzDMWTj5YccLvG7aitHDwfHBAT7nWIanD0+M8935/oFIuyML777msnzXe2We79pf3cePte8kVwLeueE6autbsTk4PjjEd8RXlMapbXx4JbUVIolJT3zvu8HxkcqrdE61xe9F8/M8MQkLvBZiqxi2ZfP80q+0+I5+qcB9HI7Uq6gUI7UQiSuZAq+RODUTXo+ISPT65+/+oUKINxMKfiESRcEvRKIo+IVIFAW/EImi4BciUXor9bUMiwthWYwoFwCA3S8dCI5vupLX25s+yRNqXnyG1xndunmC2oql8HLNz/BEkOYit40VuC5TzvMWVL+xNVxLEABuufPvB8dbkcLJWeeXQSbLJ9aqPPFk3MMS29E9vN5h5UT4PAPA4jHu4+xxLovOnAzLqdkhLm9uXs9tq4f5/XL9lbwO5fQAt72SCcfET1/eT+fMeDiBK5PjsvPrHtv1I4UQbyoU/EIkioJfiERR8AuRKAp+IRJFwS9Eoiwp9ZnZAwB+F8CUu1/XGRsD8A0AGwDsBfD77n5yyaOZIZMJSx6ZPu7KyUpYB5xf4DLayNBqant1L6+19viOvdS26crJ4PjsDJcVMwWe6VUuc9vEKJcxRybWUBs8LM1ljcuKHmnxZE2ejVbKcRlw2w23BMcPDfNMxlde3EFt1UGe4XbiCL/0ntsXPjcH979I5xQzPKtvzRi/rvrKXM7bc2qG2g7USIZegfsxuKI3Ut9fAHjfWWOfBPCIu28B8EjndyHEG4glg9/dHwVw4qzhDwB4sPPzgwA+eJH9EkJcYs73M/8qdz8EAJ3/ecUHIcRlySXf8DOze81sp5ntbES+DiqE6C3nG/xHzGwSADr/T7EHuvt97r7d3bfninxDRAjRW843+B8GcHfn57sBhAu2CSEuW7qR+r4G4E4AE2Z2AMCnAXwWwDfN7B4A+wF8uLvDOVok28v6uOyVJ4UR+4f4kfpJ4UYAGBgdprb9M1xeeXl/WK6J1ILEsSrPOOsf4rLXu29YT22ja7gM6OTPeRaxyo5czrNMZF6kBVi+EM5KHBnfQOc05sMtvgDglPFjzUxzydcKYVl3ttakc6bm+TUwsIe3lZsF/1i7Y4ZLfVP94ZNWHIqkYmYWiKH7dl1LBr+7f4SYfqvrowghLjv0DT8hEkXBL0SiKPiFSBQFvxCJouAXIlF6WsATcLRIv7tZko0GADP5sMzTiMgai7NnpyP8mlJEQVm9aoTaDhwOS1GvHpmjc1p5no22rsz9z2W5FJVv8WqnBiJ7OZdSYxl/iEmEkWxAt/Bryw1yfbZ/9TpqO37oILWdOsHXv+Th9Rgb4BfBPv50ePkQz+AsrB6ltgUbpLaDB8Py4caI/D0+Hs7qy2W7v5/rzi9Eoij4hUgUBb8QiaLgFyJRFPxCJIqCX4hE6anUZ1lDeSQsUTRrPAuPWWZOcTls8xiX7Ib6eJHDbJHLaKcQzgaszHDfF+Z5pteVkVqLtQWeBTY3zbPf+obDvniksCOT5QAg5xEnI7aMhW2xC86aPDtvgRS5BICTi3yND5IszVomfB0CwMjYGLXlnRd/HR7h8961ZRu1zT/2aHC8Xj1K5+SyYenQyLqH0J1fiERR8AuRKAp+IRJFwS9Eoij4hUiU3ib2GNDKh3eWW1W+05sphBN7ShM8aebKq3iSyInDs9T2+DO89dOeqXDdtHqD7za3wHdfT0zzDJLKIlcyavPcx0Y1rBLkSnytYmk9UWJCQCN8PhvTPEEHs7QIdDQZC5G2Z786ui98qApXOIYG+PNt2zRObZs2bKK2Le88u+nVrzHi///b/b/onBMnwwlGjUb3Nfx05xciURT8QiSKgl+IRFHwC5EoCn4hEkXBL0SidNOu6wEAvwtgyt2v64x9BsAfADidefApd//eUs/lDjQbRFjKci1nMReW+p4/ySWv5nPPUttV45PUtmotl3IquXAySN88l4b2RWTFA8d4K6+fP/EMtU1ewevgjYxNBMfLZV5DLlfspzaL3B9akVtHsxl+3fMndtE5vsDX6i3XXcPnlcKtwQBg5y/3BMcPT/Eaj8Uibw3W18ev03Vr1lDbikFue/t17wqOv3ycXwMvHHmK2rqlmzv/XwAIiZRfcPcbO/+WDHwhxOXFksHv7o8C4H8mhRBvSC7kM//HzexpM3vAzHjNYiHEZcn5Bv+XAGwGcCOAQwA+xx5oZvea2U4z29mIFF0QQvSW8wp+dz/i7k13bwH4MoBbI4+9z923u/v2XKlwvn4KIS4y5xX8ZnbmdvmHAPBtSSHEZUk3Ut/XANwJYMLMDgD4NIA7zexGtBPC9gL4w24OZgZkCuFUsDprMwXgCMn4OzzD08oO7OU1335pB6jt6JHj1FYkclmhj0tNlSr3Md/k74TGhvipqZ86TG2HX/hJ+PnGuYTZKl/Nba1IvcMWzwdkLcD27Q1LbwDQnOf7yhsz3I++Jm+hddf7bgmOP/aLF+icw5Fsy/4xvo4jE1dRW7kwwJ+TXD+lMpdgMzlyzUVaqJ3NksHv7h8JDN/f9RGEEJcl+oafEImi4BciURT8QiSKgl+IRFHwC5EoPS3gmcnxdl02y6WcQi7spg3z7KtF5wUwD54Kt3ACgGyJZ79NzYQloNkpXniyxhVMbFnN2zvdeftbqG2yj7eaemzH48HxbGEFnbPtDm7zHF8PA89wOzUdllq//8NIVl+OF5+c+BVvX3bNunAbNQD4O2/bGhxfu4Jf+j/bFS76CQA3ve23qG3lOt6Sa3qRy7OPPffj4Pj+qb10TrUZllLduy/Hqju/EImi4BciURT8QiSKgl+IRFHwC5EoCn4hEqWnUp+707529QWuidXnw3PKkWy6VoYXDimP8b51mVn+93DhWFjqazqX3sp5LiuW8+HefwCw4zGeJT0+MkJtu54PF8F8Yv8P6Zx/tfEmarty03XUxsVUoNYKy4DZIi9kecUEz3LcuI4XSZ1cxSVHz4e9HFrBn+/2d4czAQFg3bW0dAUWSH9CANi558fU9siT/zs4fmz+GJ3jRP4+l76LuvMLkSgKfiESRcEvRKIo+IVIFAW/EInS091+OIBaOIHHSaICABjJ32kY32/O9fO/a3MVvsteW+DJJdVGeDzb4st47Rbe0uCmLbxG28tP76W2F/O8TdlcPezL4jxPjDl8gisSazfxHfhmJHlqYDScEPThf3w3nWOz+6kNi7zmXrHAX1t1LrxWi3NcDRpdyxWJYj+vxbf3MPd/5+4d1DZFfKxUuHpQLocVDlI6MYju/EIkioJfiERR8AuRKAp+IRJFwS9Eoij4hUiUbtp1rQPwFQCrAbQA3OfuXzSzMQDfALAB7ZZdv+/uXIMC4C2gSVS2rPHkDMuH9YtWi2hvADJFLlEN9POkjhjj/eHlqs3wlz05xKXDTSt4QlB+w2pqe3E/byfVyIclrOtv2k7nrL3iSmqLl4Tjry1fDOuzV/1GuKYeANQam6ht9jivd3hizyPUNrXvV8HxQt96Omdk7Fpqa0ZalB06dojajp6YprZsK7xW2UirNNTJ2l9kqa8B4I/d/VoAbwfwMTPbBuCTAB5x9y0AHun8LoR4g7Bk8Lv7IXd/ovPzLIDdANYA+ACABzsPexDABy+Vk0KIi885feY3sw0AbgKwA8Aqdz8EtP9AAFh5sZ0TQlw6ug5+MxsA8G0An3B3/n3K18+718x2mtnOeuTrikKI3tJV8JtZHu3A/6q7f6czfMTMJjv2SQDBzhXufp+7b3f37XnyfWQhRO9ZMvjNzADcD2C3u3/+DNPDAE5nadwN4LsX3z0hxKWim6y+2wB8FMAuM3uyM/YpAJ8F8E0zuwfAfgAfXuqJ3B3VeriNUzPyiSBDMv4yRS41zTciGWfjXELZvI1LbOtXhmWq6f2v0jkndj1Fbfte5p+eai3ufzVSPW9yzYbg+DveeRudk83ztmeVCpcV6zWeDVgohKXWbJnXT8wVeJZjscSzIxfqkZqMI1cHx6+45k46Z5icZwBYbPJrZ2ycb3tdMbGO2loIr/ER45mHtYjk2C1LBr+7/wwAe8W8cZkQ4rJG3/ATIlEU/EIkioJfiERR8AuRKAp+IRKlpwU8M9kMBkbDLbbqdS6hNJthySMfkajmF3jG3/QcL+A5M8I1xyKRqbZew7PAXp7nctizL7/E/ZjlMuDIAJe93nJzuPVW39AQnVOt8dc8P3+U2p568klqW1wMv+7f/u330jljo+PUBvDXPDL5DmpbecWG4Hh5kEu6LZJlBwCtJj+fc9OxzD1+n63MhaVba3I/+vvCmamZTPf3c935hUgUBb8QiaLgFyJRFPxCJIqCX4hEUfALkSg9lfoMQDZD5IuIRLFA+sw1q9z9QiYsKQIAWlzaqizyjLl6Pezj6vWb6ZyV7+HZXOu3HqC2vXu4DHjq+EFq238kbFt1VYXOmX+VZyU+9K2HqO353c9RW4tU/lyY537883v+GbUV+ngBz1XrR6gtVwwXSa07l5YzkbqZ2UiFzIEC7+M3XOAZf6vHNwTHF4/ya6C2GF5Hd57peja68wuRKAp+IRJFwS9Eoij4hUgUBb8QidLT3f5Go4npo6fCtjrfRS2ThJqC8cSHhTle/6yU5fMmhieobcXoZHC8r38VnVMe4Us8MRZ+PgC4ZguvI3f46F5qm5kL14PL5rkfJ07ydmNPPf0MtU0f5/PypIbfiZM8YckjO+m1Fk+oyeV42zOjyg4/Vsv4PdEyfDd93eoN1JYp8fqEeC78nPuPhluNAUCrSVSpeH+11/rU9SOFEG8qFPxCJIqCX4hEUfALkSgKfiESRcEvRKIsKfWZ2ToAXwGwGkALwH3u/kUz+wyAPwBwusjbp9z9e7HnymQz6BsIyzK5TFgaAoBaPVyPr7bIZRePtLQajtTAGx/kte4yCCdT1GvzdE5fgSekFIo8EaTdIjHMisx6ausfDPtSrfCEmv4Slz5vedvN1PaTn/4VteXz4aasG6/eROfMzPEaeB5JxorJdg3WbCqyvq1I0o9FEtAGh/h11b84S21zc2HJNMtDAq1q+No/lyZe3ej8DQB/7O5PmNkggF+Y2Q86ti+4+386h+MJIS4TuunVdwjAoc7Ps2a2G8CaS+2YEOLSck6f+c1sA4CbAOzoDH3czJ42swfMjL/nEUJcdnQd/GY2AODbAD7h7jMAvgRgM4Ab0X5n8Dky714z22lmO+sV/pVbIURv6Sr4zSyPduB/1d2/AwDufsTdm94uHfJlALeG5rr7fe6+3d2358uRHQwhRE9ZMvitve18P4Dd7v75M8bPzEr5EACeASKEuOzoZrf/NgAfBbDLzE73Z/oUgI+Y2Y1oqwt7Afzh0k9lgIUloEqVS3O1GrFF1J9iiWd6NSN6yCsHeH28gUw4M2u0zOuzjQ7xLMFsNrwWAJCPSJXFFq9P2GqFZap6jX/kqtX5Qm6/5XpqG1vBa+dlSebkxs1r6ZxqjcuRhUgmZrPJ/W+R+1u9wS8Cj9wTY9dVPlL8b+XoCmp767Zwu7Fjc8fonOn9JKPyHLS+bnb7fwYExdKopi+EuLzRN/yESBQFvxCJouAXIlEU/EIkioJfiETpaQFPbzmqJBupzuQ8AIV8uIBnIyIN0QKHAE6c4hlWzVo4gxAArhhfDI7XG3xOtcYLT2Ziqx8pxJiNTMwR+bA4EF5DAMhHinuuWMnvD9dsvZraBgbCGYtsHADQ4FmajcgaWyQLj5kWI9Jnk2UCIi71WYufs+ESf923br0tOH7gCG+jdvTkkeA4O/8hdOcXIlEU/EIkioJfiERR8AuRKAp+IRJFwS9EovRU6rOMoVgg2VkRacsRlnmaTS7X5PIlamOZXgCQjfRUy5fC2XTNiKw4P7/An6+fZ6oVi/zUNJtczunrC9sykcKTBVJsEwAyOW4rlbh8WCC9+iySdVaphqVUAKhHMg8LZZ7lCAvLh9U6v3bmq9w22BfpuReT2SLX90AmvI7Xb7mBznnmpSeD47mMpD4hxBIo+IVIFAW/EImi4BciURT8QiSKgl+IROmp1AcHmvWw5JGJuFKvh7P3cgU+J1viUt/aNeuobduGa6jtOmIbKnP5JxuR2GLyTyOS5ZjLxU5b+HixHnMx6bNZ537k8zwLr8bkMp4wB89yP+rkugGATGWO2hoWzsJ7bu8hfqyI5Lh2YjX3A3w9YhqnkWv/qkmeNbn1yrcEx0vF/8F9OAvd+YVIFAW/EImi4BciURT8QiSKgl+IRFlyt9/MSgAeBVDsPP5b7v5pM9sI4OsAxgA8AeCj7h5tw+tNR30mvOtZr/MabfVGuA7ewOggnbNxwyZq27r5Wmrbto7vsI6VhoLjrUg9uIVFnthTmZ2ntonxMWrLWexvdnh3Ph9pd1WN7G4XCjxRpNXi58xJ8bxYEpRFaglmI8lHi3W+y/7qTNh2rMLX8C3rr6S2viJXkTyy298kCUYAYB4+N6UsV5FuvPam4HgfST4L0c2dvwrgN939BrTbcb/PzN4O4M8AfMHdtwA4CeCero8qhFh2lgx+b3NaSM13/jmA3wTwrc74gwA+eEk8FEJcErr6zG9m2U6H3ikAPwDwMoBpdz/9vu8AgDWXxkUhxKWgq+B396a73whgLYBbAYQ+NAc/zJvZvWa208x21hcjPbWFED3lnHb73X0awI8BvB3AiJmd3qFZCyDY2N7d73P37e6+PV/qvsqIEOLSsmTwm9kKMxvp/FwG8B4AuwH8CMA/6jzsbgDfvVROCiEuPt0k9kwCeNDMsmj/sfimu/9PM/slgK+b2b8H8DcA7l/ymVoAiKrkC1w2ypF6cGMjo9zpSALGVZObqW1ikEtsGdIyKpY0kymGfQeAw4cPc9vxo9S2bctWahsbGwmOz85O0zmZDE86ibXyMotk6RBibbfYeQaAvhKXKvc3+Lyfv3IsOL5meJzOuXrzRmrLRTKTMpHknVZkjbMsGYvOAMaHJoLjuWz3uXpLPtLdnwbwOlHR3feg/flfCPEGRN/wEyJRFPxCJIqCX4hEUfALkSgKfiESxTxSR+6iH8zsKIB9nV8nAIR1mN4iP16L/HgtbzQ/1rv7im6esKfB/5oDm+109+3LcnD5IT/kh972C5EqCn4hEmU5g/++ZTz2mciP1yI/Xsub1o9l+8wvhFhe9LZfiERZluA3s/eZ2fNm9pKZfXI5fOj4sdfMdpnZk2a2s4fHfcDMpszsmTPGxszsB2b2Yud/nrJ4af34jJm92lmTJ83s/T3wY52Z/cjMdpvZs2b2R53xnq5JxI+eromZlczsMTN7quPHv+uMbzSzHZ31+IaZ8XTGbnD3nv4DkEW7DNgmAAUATwHY1ms/Or7sBTCxDMe9A8DNAJ45Y+w/APhk5+dPAvizZfLjMwD+pMfrMQng5s7PgwBeALCt12sS8aOna4J2Nu9A5+c8gB1oF9D5JoC7OuN/DuBfXshxluPOfyuAl9x9j7dLfX8dwAeWwY9lw90fBXDirOEPoF0IFehRQVTiR89x90Pu/kTn51m0i8WsQY/XJOJHT/E2l7xo7nIE/xoAr5zx+3IW/3QA3zezX5jZvcvkw2lWufshoH0RAli5jL583Mye7nwsuOQfP87EzDagXT9iB5ZxTc7yA+jxmvSiaO5yBH+oQMlySQ63ufvNAH4HwMfM7I5l8uNy4ksANqPdo+EQgM/16sBmNgDg2wA+4e4zvTpuF370fE38AormdstyBP8BAOvO+J0W/7zUuPvBzv9TAB7C8lYmOmJmkwDQ+X9qOZxw9yOdC68F4Mvo0ZqYWR7tgPuqu3+nM9zzNQn5sVxr0jn2ORfN7ZblCP7HAWzp7FwWANwF4OFeO2Fm/WY2ePpnAO8F8Ex81iXlYbQLoQLLWBD1dLB1+BB6sCbWLgZ4P4Dd7v75M0w9XRPmR6/XpGdFc3u1g3nWbub70d5JfRnAny6TD5vQVhqeAvBsL/0A8DW03z7W0X4ndA+AcQCPAHix8//YMvnx3wDsAvA02sE32QM/3oX2W9inATzZ+ff+Xq9JxI+ergmA69Euivs02n9o/u0Z1+xjAF4C8N8BFC/kOPqGnxCJom/4CZEoCn4hEkXBL0SiKPiFSBQFvxCJouAXf0sne+1PltsP0RsU/EIkioI/cczsTzu1FX4IYGtn7EYz++tOIstDpxNZzOyWztjPzew/nlkHQLzxUPAnjJm9Fe2vV98E4B8AuKVj+gqAf+3u16P9zbZPd8b/K4B/4e7vANDssbviIqPgT5vbATzk7gvezl57GEA/gBF3/0nnMQ8CuKPzXfNBd/+rzvhf9t5dcTFR8ItmVRTrAAAAuUlEQVRuv98dSsUWb2AU/GnzKIAPmVm5k+H4ewDmAZw0s9s7j/kogJ+4+0kAs2b29s74Xb13V1xMcks/RLxZcfcnzOwbaGev7QPw047pbgB/bmZ9APYA+Ked8XsAfNnM5tHOMT/VW4/FxURZfaJrzGzAO7XlOlWXJ939j5bZLXGe6M4vzoW/Z2b/Bu3rZh+Af7K87ogLQXd+IRJFG35CJIqCX4hEUfALkSgKfiESRcEvRKIo+IVIlP8PAGp4Oz3hgcQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Try using the dataloader to print one image\n",
    "for i_batch, sample_batched in enumerate(trainloader):\n",
    "    print(\"Batch information: \", i_batch, sample_batched['image'].size(), sample_batched['label'])\n",
    "    showImage(sample_batched['image'][0],getLabel(sample_batched['label'][0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the neural net.\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        #Define the network\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 5) #We have 3 channels. Output 6 feature map with 5x5 kernel\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(8, 20, 5) #We have 6 channels. Output 20 feature map with 5x5 kernel\n",
    "        self.fc1 = nn.Linear(20 * 5 * 5, 60)\n",
    "        self.fc2 = nn.Linear(60, 10)\n",
    "        \n",
    "        # Adding a layer for LogSoftmax to obtain log probabilities\n",
    "        # As recommended in documentation for Negative log likelihood loss https://pytorch.org/docs/stable/nn.html#nllloss\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 20 * 5 * 5)\n",
    "        x = self.fc1(x)\n",
    "        x = self.logsoftmax(self.fc2(x))\n",
    "        return(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(8, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=500, out_features=60, bias=True)\n",
      "  (fc2): Linear(in_features=60, out_features=10, bias=True)\n",
      "  (logsoftmax): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Initialize the neural net\n",
    "classifier = CNN()\n",
    "classifier.to(device)\n",
    "print(classifier)\n",
    "#Create the optim\n",
    "optimizer = optim.SGD(classifier.parameters(), lr=0.005, momentum=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a520ad5ffbdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#Load batches from our trainLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mLossAggregate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_batched\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m#Get our data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;31m# need to call `.task_done()` because we don't use `.join()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrebuild_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mident\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;34m'''Return connection from which to receive identified resource.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LossCount = []\n",
    "for epoch in range(10):\n",
    "    #Load batches from our trainLoader\n",
    "    LossAggregate = 0\n",
    "    for i_batch, sample_batched in enumerate(trainloader):\n",
    "        \n",
    "        #Get our data\n",
    "        image = sample_batched['image']\n",
    "        label = sample_batched['label']\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        # zero the gradient of optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        output = classifier(image)\n",
    "        # Use Negative Likelihood Loss\n",
    "        loss = nn.NLLLoss()(output, label)\n",
    "        \n",
    "        #Record stats for every 100. Print average loss.\n",
    "        LossAggregate += loss.item()\n",
    "        if i_batch % 5000 == 4999: # print every 5000 batches (25000 images) \n",
    "            print('Epoch: %d. Minibatches %d loss %.3f' % (epoch + 1, i_batch+1, LossAggregate / 5000))\n",
    "            LossCount.append(LossAggregate/5000)\n",
    "            LossAggregate = 0.0\n",
    "            \n",
    "        #Propagate our losses\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i_batch, sample_batched in enumerate(testloader):\n",
    "\n",
    "        #Get our data\n",
    "        image = sample_batched['image']\n",
    "        label = sample_batched['label']\n",
    "        #Foward pass\n",
    "        output = classifier(image.type('torch.FloatTensor'))\n",
    "        value = torch.max(output.data,1)[1]\n",
    "        total += 1\n",
    "        if value == label:\n",
    "            correct += 1\n",
    "print('Accuracy on our 10000 test set is %d percent' % (100 * correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
